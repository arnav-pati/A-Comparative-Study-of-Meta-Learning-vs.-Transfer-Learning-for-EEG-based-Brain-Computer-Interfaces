{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnav-pati/Meta-Learning-to-improve-EEG-Motor-Imagery-Classification/blob/main/bciiv2a_Reptile_EEGNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u7ukG6WGeJ4",
        "outputId": "e7a3e170-4873-4e3d-d6bf-1c9a56973444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpI3QHvmGk-H",
        "outputId": "420a938d-813e-43ac-b2c1-49a68246bbea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/EEGdatasets\n"
          ]
        }
      ],
      "source": [
        "%cd gdrive/MyDrive/EEGdatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SGOu-RBnG2X3",
        "outputId": "5d0edd09-5d57-42ef-ec20-d6dd5e72f42d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/EEGdatasets'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-M3CTMr8Mga"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHi4rC2BEX3b",
        "outputId": "b8dcbec9-c5bc-4874-eccf-8e31260d787c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iQTSS3j_OG2x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim, autograd\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tensorboardX import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import os.path\n",
        "import errno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEIsVcLAf-Gq",
        "outputId": "7b7f7fdc-ebf4-4178-b775-32c67075ee20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8iMg76_Gx5KY"
      },
      "outputs": [],
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJmk-VIw8Xw_"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataNShot():\n",
        "\tdef __init__(self, root, data_npy, train_subj, test_subj, batchsz, n_way, k_shot, k_query, eeg_shape, num_trials, batchst=1):\n",
        "\t\tself.num_trials = num_trials\n",
        "\t\tself.batchsz = {\"train\": batchsz, \"test\": batchst}\n",
        "\t\tself.n_way = n_way\n",
        "\t\tself.k_shot = k_shot\n",
        "\t\tself.k_query = k_query\n",
        "\t\tself.eeg_shape = eeg_shape\n",
        "\t\tself.root = root\n",
        "\t\tself.data_npy = data_npy\n",
        "\t\tself.train_subj = train_subj\n",
        "\t\tself.test_subj = test_subj\n",
        "\t\tself.subj = {\"train\": self.train_subj, \"test\": self.test_subj}\n",
        "\n",
        "\tdef get_data(self, mode, subj, cls, trial):\n",
        "\t\treturn np.load(os.path.join(self.root, self.data_npy+'_'+mode, f\"s{subj}_c{cls}_t{trial}.npy\"))\n",
        "\n",
        "\tdef get_batch(self, mode):\n",
        "\t\tsetsz = self.k_shot * self.n_way\n",
        "\t\tquerysz = self.k_query * self.n_way\n",
        "\t\tnum_subj = self.subj[mode]\n",
        "\n",
        "\t\tsupport_x = np.zeros((self.batchsz[mode], setsz) + self.eeg_shape)\n",
        "\t\tsupport_y = np.zeros((self.batchsz[mode], setsz), dtype=int)\n",
        "\t\tquery_x = np.zeros((self.batchsz[mode], querysz) + self.eeg_shape)\n",
        "\t\tquery_y = np.zeros((self.batchsz[mode], querysz), dtype=int)\n",
        "\n",
        "\t\tselected_tasks = np.random.choice(num_subj, self.batchsz[mode], False)\n",
        "\t\tfor i, cur_task in enumerate(selected_tasks):\n",
        "\t\t\tshuffle_idx = np.arange(self.n_way)\n",
        "\t\t\tnp.random.shuffle(shuffle_idx)\n",
        "\t\t\tshuffle_idx_test = np.arange(self.n_way)\n",
        "\t\t\tnp.random.shuffle(shuffle_idx_test)\n",
        "\n",
        "\t\t\tfor j in range(self.n_way):\n",
        "\t\t\t\tselected_data = np.random.choice(self.num_trials, self.k_shot + self.k_query, False)\n",
        "\n",
        "\t\t\t\tfor offset, eeg in enumerate(selected_data[:self.k_shot]):\n",
        "\t\t\t\t\tsupport_x[i, shuffle_idx[j] * self.k_shot + offset, ...] = self.get_data(mode, cur_task, j, eeg)\n",
        "\t\t\t\t\tsupport_y[i, shuffle_idx[j] * self.k_shot + offset] = j\n",
        "\n",
        "\t\t\t\tfor offset, eeg in enumerate(selected_data[self.k_shot:]):\n",
        "\t\t\t\t\t\tquery_x[i, shuffle_idx_test[j] * self.k_query + offset, ...] = self.get_data(mode, cur_task, j, eeg)\n",
        "\t\t\t\t\t\tquery_y[i, shuffle_idx_test[j] * self.k_query + offset] = j\n",
        "\t\n",
        "\t\treturn support_x, support_y, query_x, query_y"
      ],
      "metadata": {
        "id": "FB7-dDh2HgO9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iugBQ90vYdkZ"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, db, mode, k_shot, k_query) -> None:\n",
        "        super().__init__()\n",
        "        # self.data = data\n",
        "        self.db = db\n",
        "        self.mode = mode\n",
        "        self.shape = (len(db.subj[mode]), db.n_way, db.num_trials) + db.eeg_shape\n",
        "        self.n_way = self.shape[1]\n",
        "        self.k_shot = k_shot\n",
        "        self.k_query = k_query\n",
        "        self.out_shape = (self.n_way * self.k_shot,) + self.shape[-2:]\n",
        "        self.out_shape_query = (self.n_way * self.k_query,) + self.shape[-2:]\n",
        "        self.shuffle_idx = np.zeros(self.shape[:3], dtype=int)\n",
        "        for p in range(self.shape[0]):\n",
        "            for q in range(self.shape[1]):\n",
        "                idx_range = np.arange(self.shape[2])\n",
        "                np.random.shuffle(idx_range)\n",
        "                self.shuffle_idx[p, q, ...] = idx_range\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.shape[0] * (self.shape[2] // (self.k_shot + self.k_query))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        idx2 = (self.k_shot + self.k_query) * (idx // self.shape[0])\n",
        "        idx0 = idx % self.shape[0]\n",
        "\n",
        "        support_x = np.zeros(self.out_shape)\n",
        "        support_y = np.zeros(self.out_shape[:1], dtype=int)\n",
        "        query_x = np.zeros(self.out_shape_query)\n",
        "        query_y = np.zeros(self.out_shape_query[:1], dtype=int)\n",
        "        \n",
        "        for j in range(self.n_way):\n",
        "            # support_x[(j*self.k_shot):((j+1)*self.k_shot), ...] = self.data[idx0][j][self.shuffle_idx[idx0, j, idx2:idx2+self.k_shot]]\n",
        "            for v in range(self.k_shot):\n",
        "                support_x[(j*self.k_shot) + v, ...] = self.db.get_data(self.mode, self.db.subj[self.mode][idx0], j, self.shuffle_idx[idx0, j, idx2+v])\n",
        "            support_y[(j*self.k_shot):((j+1)*self.k_shot)] = j\n",
        "\n",
        "            # query_x[(j*self.k_query):((j+1)*self.k_query), ...] = self.data[idx0][j][self.shuffle_idx[idx0, j, idx2+self.k_shot:idx2+self.k_shot+self.k_query]]\n",
        "            for v in range(self.k_query):\n",
        "                query_x[(j*self.k_query) + v, ...] = self.db.get_data(self.mode, self.db.subj[self.mode][idx0], j, self.shuffle_idx[idx0, j, idx2+self.k_shot+v])\n",
        "            query_y[(j*self.k_query):((j+1)*self.k_query)] = j\n",
        "        \n",
        "        return support_x, support_y, query_x, query_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vfh3UNT8r-u"
      },
      "source": [
        "# Reptile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CJN25DcUOmCR"
      },
      "outputs": [],
      "source": [
        "class Learner(nn.Module):\n",
        "    '''\n",
        "    It stores a specific nn.Module class\n",
        "    '''\n",
        "\n",
        "    def __init__(self, net_class, *args) -> None:\n",
        "        '''\n",
        "        net_class is a class, not an instance\n",
        "        args: the parameters for net_class\n",
        "        '''\n",
        "        super(Learner, self).__init__()\n",
        "        assert net_class.__class__ == type\n",
        "\n",
        "        self.net = net_class(*args).to(DEVICE)\n",
        "        self.net_pi = net_class(*args).to(DEVICE)\n",
        "        self.learner_lr = 0.1\n",
        "        self.optimizer = optim.SGD(self.net_pi.parameters(), self.learner_lr)\n",
        "    \n",
        "    def parameters(self):\n",
        "        '''\n",
        "        ignore self.net_pi.parameters()\n",
        "        '''\n",
        "        return self.net.parameters()\n",
        "    \n",
        "    def update_pi(self):\n",
        "        for m_from, m_to in zip(self.net.modules(), self.net_pi.modules()):\n",
        "            if isinstance(m_to, nn.Linear) or isinstance(m_to, nn.Conv2d) or isinstance(m_to, nn.BatchNorm2d):\n",
        "                m_to.weight.data = m_from.weight.data.clone()\n",
        "                if m_to.bias is not None:\n",
        "                    m_to.bias.data = m_from.bias.data.clone()\n",
        "    \n",
        "    def forward(self, support_x, support_y, query_x, query_y, num_updates, testing=False):\n",
        "        self.update_pi()\n",
        "        if testing:\n",
        "            self.net_pi.freeze()\n",
        "        for i in range(num_updates):\n",
        "            loss, pred = self.net_pi(support_x, support_y)\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "        if testing:\n",
        "            self.net_pi.unfreeze()\n",
        "        loss, pred = self.net_pi(query_x, query_y)\n",
        "        indices = torch.argmax(pred, dim=1)\n",
        "        correct = torch.eq(indices, query_y).sum().item()\n",
        "        acc = correct / query_y.size(0)\n",
        "        \n",
        "        grads_pi = autograd.grad(loss, self.net_pi.parameters(), create_graph=True)\n",
        "        return loss, grads_pi, acc\n",
        "    \n",
        "    def net_forward(self, support_x, support_y):\n",
        "        loss, pred = self.net(support_x, support_y)\n",
        "        return loss, pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ho8tgFrBsi5V"
      },
      "outputs": [],
      "source": [
        "class MetaLearner(nn.Module):\n",
        "    def __init__(self, net_class, net_class_args, n_way, k_shot, meta_batchesz, beta, num_updates, num_updates_test) -> None:\n",
        "        super(MetaLearner, self).__init__()\n",
        "        self.n_way = n_way\n",
        "        self.k_shot = k_shot\n",
        "        self.meta_batchesz = meta_batchesz\n",
        "        self.beta = beta\n",
        "        self.num_updates = num_updates\n",
        "        self.num_updates_test = num_updates_test\n",
        "\n",
        "        self.learner = Learner(net_class, *net_class_args)\n",
        "        self.optimizer = optim.Adam(self.learner.parameters(), lr=beta)\n",
        "    \n",
        "    def write_grads(self, dummy_loss, sum_grads_pi):\n",
        "        hooks = []\n",
        "        for i, v in enumerate(self.learner.parameters()):\n",
        "            def closure():\n",
        "                ii = i\n",
        "                return lambda grad : sum_grads_pi[ii]\n",
        "            # h = v.register_hook(closure())\n",
        "            hooks.append(v.register_hook(closure()))\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "        dummy_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        for h in hooks:\n",
        "            h.remove()\n",
        "    \n",
        "    def forward(self, support_x, support_y, query_x, query_y):\n",
        "        sum_grads_pi = None\n",
        "        meta_batchesz = support_y.size(0)\n",
        "\n",
        "        accs = []\n",
        "        for i in range(meta_batchesz):\n",
        "            _, grad_pi, episode_acc = self.learner(support_x[i], support_y[i], query_x[i], query_y[i], self.num_updates)\n",
        "            accs.append(episode_acc)\n",
        "            if sum_grads_pi is None:\n",
        "                sum_grads_pi = grad_pi\n",
        "            else:\n",
        "                sum_grads_pi = [torch.add(p, q) for p, q in zip(sum_grads_pi, grad_pi)]\n",
        "        dummy_loss, _ = self.learner.net_forward(support_x[0], support_y[0])\n",
        "        self.write_grads(dummy_loss, sum_grads_pi)\n",
        "\n",
        "        return accs\n",
        "    \n",
        "    def pred(self, support_x, support_y, query_x, query_y):\n",
        "        meta_batchesz = support_y.size(0)\n",
        "        accs = []\n",
        "        for i in range(meta_batchesz):\n",
        "            _, _, episode_acc = self.learner(support_x[i], support_y[i], query_x[i], query_y[i], self.num_updates_test, testing=True)\n",
        "            accs.append(episode_acc)\n",
        "        return np.array(accs).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xEOqW8k9Mvm"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qDZy2ATi26E6"
      },
      "outputs": [],
      "source": [
        "class EEGNet(nn.Module):\n",
        "    def __init__(self, nb_classes, Chans = 22, Samples = 1001,\n",
        "                 dropoutRate = 0.5, kernLength = 64, F1 = 8,\n",
        "                 D = 2, F2 = 16, norm_rate = 0.25) -> None:\n",
        "        super().__init__()\n",
        "        self.device = DEVICE\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(1, F1, (1, kernLength), padding='same', bias=False),\n",
        "            nn.BatchNorm2d(F1),\n",
        "            nn.Conv2d(F1, F1 * D, (Chans, 1), groups=F1, bias=False),\n",
        "            nn.BatchNorm2d(F1 * D),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 4)),\n",
        "            nn.Dropout(dropoutRate)\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(F2, F2, (1, 16), padding='same', bias=False),\n",
        "            nn.Conv2d(F2, F2, 1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(F2),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 8)),\n",
        "            nn.Dropout(dropoutRate)\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        self.block_weights = ['block1.0.weight', 'block1.1.weight', 'block1.1.bias', 'block1.2.weight', 'block1.3.weight', 'block1.3.bias', 'block2.0.weight', 'block2.1.weight', 'block2.2.weight', 'block2.2.bias']\n",
        "\n",
        "        self.classifier_input = 16 * ((Samples // 4) // 8)\n",
        "        self.classifier_hidden = int((self.classifier_input * nb_classes) ** 0.5)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(self.classifier_input, self.classifier_hidden),\n",
        "            nn.Linear(self.classifier_hidden, nb_classes)\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "    \n",
        "    def forward(self, x, target=None):\n",
        "        x = self.block1(torch.unsqueeze(x, 1))\n",
        "        x = self.block2(x)\n",
        "        pred = self.classifier(x)\n",
        "\n",
        "        loss = self.criterion(pred, target)\n",
        "        return loss, pred\n",
        "    \n",
        "    def freeze(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if name in self.block_weights:\n",
        "                param.requires_grad = False\n",
        "    \n",
        "    def unfreeze(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if name in self.block_weights:\n",
        "                param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zla3N3Q4AjoT"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1zOmHxNgAjDL"
      },
      "outputs": [],
      "source": [
        "def meta_train(db, meta, iterations):\n",
        "    tb = SummaryWriter('runs')\n",
        "    for episode_num in range(iterations):\n",
        "        support_x, support_y, query_x, query_y = db.get_batch('train')\n",
        "        support_x = Variable( torch.from_numpy(support_x).float()).to(DEVICE)\n",
        "        query_x = Variable( torch.from_numpy(query_x).float()).to(DEVICE)\n",
        "        support_y = Variable(torch.from_numpy(support_y).long()).to(DEVICE)\n",
        "        query_y = Variable(torch.from_numpy(query_y).long()).to(DEVICE)\n",
        "\n",
        "        accs = meta(support_x, support_y, query_x, query_y)\n",
        "        train_acc = 100 * np.array(accs).mean()\n",
        "\n",
        "        if episode_num % 50 == 0:\n",
        "            test_accs = []\n",
        "            for i in range(min(episode_num // 5000 + 3, 10)):\n",
        "                support_x, support_y, query_x, query_y = db.get_batch('test')\n",
        "                support_x = Variable( torch.from_numpy(support_x).float()).to(DEVICE)\n",
        "                query_x = Variable( torch.from_numpy(query_x).float()).to(DEVICE)\n",
        "                support_y = Variable(torch.from_numpy(support_y).long()).to(DEVICE)\n",
        "                query_y = Variable(torch.from_numpy(query_y).long()).to(DEVICE)\n",
        "\n",
        "                test_acc = meta.pred(support_x, support_y, query_x, query_y)\n",
        "                test_accs.append(test_acc)\n",
        "\n",
        "            test_acc = 100 * np.array(test_accs).mean()\n",
        "            print('episode:', episode_num, '\\tfinetune acc:%.6f' % train_acc, '\\t\\ttest acc:%.6f' % test_acc)\n",
        "            tb.add_scalar('test-acc', test_acc)\n",
        "            tb.add_scalar('finetune-acc', train_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tyIY9Otl3WO_"
      },
      "outputs": [],
      "source": [
        "def train(net, train_loader, epochs):\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "    train_log = []\n",
        "    val_log = []\n",
        "    for epoch in range(epochs):\n",
        "        accs = []\n",
        "        train_loss = []\n",
        "        val_loss = []\n",
        "        for support_x, support_y, query_x, query_y in tqdm(train_loader):\n",
        "            support_x = Variable(support_x[0].float()).to(DEVICE)\n",
        "            query_x = Variable(query_x[0].float()).to(DEVICE)\n",
        "            support_y = Variable(support_y[0].long()).to(DEVICE)\n",
        "            query_y = Variable(query_y[0].long()).to(DEVICE)\n",
        "\n",
        "            net.train()\n",
        "            loss, pred = net(support_x, support_y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "            net.eval()\n",
        "            loss, pred = net(query_x, query_y)\n",
        "            val_loss.append(loss.item())\n",
        "            indices = torch.argmax(pred, dim=1)\n",
        "            correct = torch.eq(indices, query_y).sum().item()\n",
        "            acc = correct / query_y.size(0)\n",
        "            accs.append(acc)\n",
        "        train_loss = np.array(train_loss).mean()\n",
        "        train_log.append(train_loss)\n",
        "        val_loss = np.array(val_loss).mean()\n",
        "        val_log.append(val_loss)\n",
        "        accuracy = 100 * np.array(accs).mean()\n",
        "        print(f'Epoch {epoch+1}:', '\\tvalidation acc: %.6f' % accuracy, '\\tvalidation loss: %.6f' % val_loss, '\\ttrain loss: %.6f' % train_loss)\n",
        "    plt.plot(train_log)\n",
        "    plt.plot(val_log)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b-uSdMbAVSp"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(learner, db, min_updates_test=5, max_updates_test=150):\n",
        "    test_loader = DataLoader(\n",
        "        dataset = CustomDataset(db, \"test\", k_shot=0, k_query=4),\n",
        "        batch_size = 1\n",
        "    )\n",
        "    accs = []\n",
        "    for support_x, support_y, query_x, query_y in test_loader:\n",
        "        support_x = Variable(support_x[0].float()).to(DEVICE)\n",
        "        query_x = Variable(query_x[0].float()).to(DEVICE)\n",
        "        support_y = Variable(support_y[0].long()).to(DEVICE)\n",
        "        query_y = Variable(query_y[0].long()).to(DEVICE)\n",
        "        _, _, episode_acc = learner(support_x, support_y, query_x, query_y, 0, testing=True)\n",
        "        accs.append(episode_acc)\n",
        "    accs = 100 * np.array(accs)\n",
        "    \n",
        "    results = [{\"mean\":accs.mean(), \"std\":accs.std(), \"num_upd\":0}]\n",
        "    print(f\"{0}-shot accuracy: \\tmean: {results[0]['mean']:.6f}{'%'}\\tstd: {results[0]['std']:.6f}{'%'}\")\n",
        "\n",
        "    for K in range(1, 11):\n",
        "        dct = {\"mean\":0, \"std\":0, \"num_upd\":0}\n",
        "        for num_updates_test in tqdm(range(min_updates_test, max_updates_test, 2)):\n",
        "            test_loader = DataLoader(\n",
        "                dataset = CustomDataset(db, \"test\", k_shot=K, k_query=4),\n",
        "                batch_size = 1\n",
        "            )\n",
        "            accs = []\n",
        "            for support_x, support_y, query_x, query_y in test_loader:\n",
        "                support_x = Variable(support_x[0].float()).to(DEVICE)\n",
        "                query_x = Variable(query_x[0].float()).to(DEVICE)\n",
        "                support_y = Variable(support_y[0].long()).to(DEVICE)\n",
        "                query_y = Variable(query_y[0].long()).to(DEVICE)\n",
        "                _, _, episode_acc = learner(support_x, support_y, query_x, query_y, num_updates_test, testing=True)\n",
        "                accs.append(episode_acc)\n",
        "            accs = 100 * np.array(accs)\n",
        "            if accs.mean() > dct[\"mean\"]:\n",
        "                dct[\"mean\"] = accs.mean()\n",
        "                dct[\"std\"] = accs.std()\n",
        "                dct[\"num_upd\"] = num_updates_test\n",
        "\n",
        "        results.append(dct)\n",
        "        print(f\"{K}-shot accuracy: \\tmean: {dct['mean']:.6f}{'%'}\\tstd: {dct['std']:.6f}{'%'}\\tafter {dct['num_upd']} updates\")\n",
        "    \n",
        "    return results"
      ],
      "metadata": {
        "id": "wU-1_-8wihUF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfj3z0d39Vq3"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Mnxtf3mAB_Vn"
      },
      "outputs": [],
      "source": [
        "def bciiv2a(model, iterations=30000, epochs=100, Reptile=True):\n",
        "    root = ''\n",
        "    data_npy = 'bciiv2a'\n",
        "    # dataset = BNCI2014001()\n",
        "    meta_batchsz = 5\n",
        "    n_way = 4\n",
        "    k_shot = 4\n",
        "    k_query = k_shot\n",
        "\n",
        "    meta_lr = 1e-3\n",
        "    num_updates = 2\n",
        "    num_updates_test = 10\n",
        "\n",
        "    # fmin, fmax = 4, 32\n",
        "    # raw = dataset.get_data(subjects=[1])[1]['session_T']['run_1']\n",
        "    # dataset_channels = raw.pick_types(eeg=True).ch_names\n",
        "    # sfreq = 250.\n",
        "    # prgm_MI_classes = MotorImagery(n_classes=4, channels=dataset_channels, resample=sfreq, fmin=fmin, fmax=fmax)\n",
        "\n",
        "    train_subj = list(range(1,9))\n",
        "    test_subj = [9]\n",
        "\n",
        "    db = DataNShot(root, data_npy, train_subj, test_subj, meta_batchsz, n_way, k_shot, k_query, (22, 1001), 144)\n",
        "\n",
        "    if Reptile:\n",
        "        meta = MetaLearner(model, (4, 22, 1001), n_way=n_way, k_shot=k_shot, meta_batchesz=meta_batchsz, beta=meta_lr, num_updates=num_updates, num_updates_test=num_updates_test).to(DEVICE)\n",
        "        meta_train(db, meta, iterations)\n",
        "        return meta.learner, db\n",
        "    else:\n",
        "        net = model(4, 22, 1001).to(DEVICE)\n",
        "\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(42)\n",
        "        train_loader = DataLoader(\n",
        "            dataset = CustomDataset(db, \"train\", k_shot=k_shot, k_query=1),\n",
        "            batch_size = 1,\n",
        "            shuffle = True,\n",
        "            worker_init_fn=seed_worker,\n",
        "            generator=g\n",
        "        )\n",
        "        train(net, train_loader, epochs)\n",
        "        net_trained = Learner(model, 4, 22, 1001)\n",
        "        net_trained.net = net\n",
        "        return net_trained, db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rubd_ISw9aBR"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ockhKGcQGfKS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f201a76-6b8f-467e-f289-ea348beddf17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/224 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "100%|██████████| 224/224 [15:04<00:00,  4.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: \tvalidation acc: 33.147321 \tvalidation loss: 1.411804 \ttrain loss: 1.320304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: \tvalidation acc: 37.165179 \tvalidation loss: 1.419649 \ttrain loss: 1.251284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: \tvalidation acc: 39.174107 \tvalidation loss: 1.411752 \ttrain loss: 1.181449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: \tvalidation acc: 41.629464 \tvalidation loss: 1.403816 \ttrain loss: 1.144400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: \tvalidation acc: 45.647321 \tvalidation loss: 1.402468 \ttrain loss: 1.121700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:08<00:00, 25.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: \tvalidation acc: 43.191964 \tvalidation loss: 1.388070 \ttrain loss: 1.097016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: \tvalidation acc: 45.424107 \tvalidation loss: 1.394015 \ttrain loss: 1.073069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: \tvalidation acc: 45.200893 \tvalidation loss: 1.363247 \ttrain loss: 1.044923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: \tvalidation acc: 45.312500 \tvalidation loss: 1.401073 \ttrain loss: 1.040593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: \tvalidation acc: 47.767857 \tvalidation loss: 1.375256 \ttrain loss: 1.017204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: \tvalidation acc: 47.656250 \tvalidation loss: 1.361202 \ttrain loss: 1.013709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: \tvalidation acc: 47.098214 \tvalidation loss: 1.412584 \ttrain loss: 1.003235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: \tvalidation acc: 47.656250 \tvalidation loss: 1.388196 \ttrain loss: 0.982872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: \tvalidation acc: 47.991071 \tvalidation loss: 1.363117 \ttrain loss: 0.992929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:08<00:00, 25.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: \tvalidation acc: 52.008929 \tvalidation loss: 1.320694 \ttrain loss: 0.971379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: \tvalidation acc: 50.669643 \tvalidation loss: 1.341866 \ttrain loss: 0.952250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: \tvalidation acc: 51.339286 \tvalidation loss: 1.389011 \ttrain loss: 0.953919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 23.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: \tvalidation acc: 51.450893 \tvalidation loss: 1.369192 \ttrain loss: 0.944495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:08<00:00, 25.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: \tvalidation acc: 51.785714 \tvalidation loss: 1.353319 \ttrain loss: 0.941315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:08<00:00, 24.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: \tvalidation acc: 51.785714 \tvalidation loss: 1.384572 \ttrain loss: 0.935303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: \tvalidation acc: 52.343750 \tvalidation loss: 1.319867 \ttrain loss: 0.928406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: \tvalidation acc: 52.008929 \tvalidation loss: 1.331733 \ttrain loss: 0.941590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: \tvalidation acc: 51.116071 \tvalidation loss: 1.334190 \ttrain loss: 0.932522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: \tvalidation acc: 50.892857 \tvalidation loss: 1.397573 \ttrain loss: 0.928586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: \tvalidation acc: 51.674107 \tvalidation loss: 1.375245 \ttrain loss: 0.920369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: \tvalidation acc: 50.446429 \tvalidation loss: 1.363962 \ttrain loss: 0.910469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: \tvalidation acc: 51.339286 \tvalidation loss: 1.368986 \ttrain loss: 0.917957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: \tvalidation acc: 51.562500 \tvalidation loss: 1.355475 \ttrain loss: 0.903821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: \tvalidation acc: 52.678571 \tvalidation loss: 1.341188 \ttrain loss: 0.911923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: \tvalidation acc: 51.004464 \tvalidation loss: 1.340070 \ttrain loss: 0.909780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: \tvalidation acc: 51.785714 \tvalidation loss: 1.359004 \ttrain loss: 0.897586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32: \tvalidation acc: 51.339286 \tvalidation loss: 1.345137 \ttrain loss: 0.905208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:08<00:00, 25.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33: \tvalidation acc: 52.343750 \tvalidation loss: 1.410367 \ttrain loss: 0.889314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34: \tvalidation acc: 52.901786 \tvalidation loss: 1.377826 \ttrain loss: 0.883092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35: \tvalidation acc: 54.464286 \tvalidation loss: 1.341786 \ttrain loss: 0.879408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36: \tvalidation acc: 52.566964 \tvalidation loss: 1.352286 \ttrain loss: 0.890779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37: \tvalidation acc: 52.566964 \tvalidation loss: 1.350420 \ttrain loss: 0.876097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38: \tvalidation acc: 51.897321 \tvalidation loss: 1.369367 \ttrain loss: 0.873543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39: \tvalidation acc: 52.455357 \tvalidation loss: 1.352263 \ttrain loss: 0.863177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40: \tvalidation acc: 53.906250 \tvalidation loss: 1.325740 \ttrain loss: 0.866368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41: \tvalidation acc: 53.794643 \tvalidation loss: 1.345642 \ttrain loss: 0.865710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 23.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42: \tvalidation acc: 54.129464 \tvalidation loss: 1.322288 \ttrain loss: 0.858680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43: \tvalidation acc: 53.348214 \tvalidation loss: 1.369036 \ttrain loss: 0.871307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44: \tvalidation acc: 54.017857 \tvalidation loss: 1.317195 \ttrain loss: 0.852981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45: \tvalidation acc: 54.241071 \tvalidation loss: 1.346162 \ttrain loss: 0.857431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:08<00:00, 25.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46: \tvalidation acc: 54.799107 \tvalidation loss: 1.316592 \ttrain loss: 0.864980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47: \tvalidation acc: 51.897321 \tvalidation loss: 1.364172 \ttrain loss: 0.855036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48: \tvalidation acc: 54.241071 \tvalidation loss: 1.331327 \ttrain loss: 0.861412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:09<00:00, 24.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49: \tvalidation acc: 53.571429 \tvalidation loss: 1.387604 \ttrain loss: 0.830026\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "bciiv2a_EEGNet, bciiv2a_data = bciiv2a(EEGNet, epochs=49, Reptile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bhZRDFBqdQ4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ce655a-0772-4fd4-fc01-8ed4f8e41c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0-shot accuracy: \tmean: 58.854167%\tstd: 9.589559%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [05:06<00:00,  4.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-shot accuracy: \tmean: 58.258929%\tstd: 13.051834%\tafter 73 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [04:32<00:00,  3.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-shot accuracy: \tmean: 63.541667%\tstd: 13.700986%\tafter 67 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:53<00:00,  3.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3-shot accuracy: \tmean: 63.437500%\tstd: 11.052962%\tafter 113 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:37<00:00,  2.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4-shot accuracy: \tmean: 65.277778%\tstd: 14.316339%\tafter 103 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:26<00:00,  2.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-shot accuracy: \tmean: 68.750000%\tstd: 12.103073%\tafter 135 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:28<00:00,  2.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6-shot accuracy: \tmean: 66.964286%\tstd: 12.814911%\tafter 71 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:38<00:00,  3.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7-shot accuracy: \tmean: 69.711538%\tstd: 11.458053%\tafter 97 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:45<00:00,  3.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8-shot accuracy: \tmean: 69.791667%\tstd: 11.073069%\tafter 147 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:50<00:00,  3.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9-shot accuracy: \tmean: 66.477273%\tstd: 9.709095%\tafter 145 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:50<00:00,  3.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-shot accuracy: \tmean: 68.125000%\tstd: 8.592329%\tafter 37 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results_bciiv2a_EEGNet = evaluate(bciiv2a_EEGNet, bciiv2a_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ojoj57zUb2Vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5594f9-d42a-4106-e0be-e1e8e457e106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 0 \tfinetune acc:20.000000 \t\ttest acc:20.833333\n",
            "episode: 50 \tfinetune acc:42.500000 \t\ttest acc:52.083333\n",
            "episode: 100 \tfinetune acc:41.250000 \t\ttest acc:45.833333\n",
            "episode: 150 \tfinetune acc:46.250000 \t\ttest acc:60.416667\n",
            "episode: 200 \tfinetune acc:41.250000 \t\ttest acc:50.000000\n",
            "episode: 250 \tfinetune acc:43.750000 \t\ttest acc:66.666667\n",
            "episode: 300 \tfinetune acc:51.250000 \t\ttest acc:52.083333\n",
            "episode: 350 \tfinetune acc:56.250000 \t\ttest acc:56.250000\n",
            "episode: 400 \tfinetune acc:46.250000 \t\ttest acc:56.250000\n",
            "episode: 450 \tfinetune acc:48.750000 \t\ttest acc:50.000000\n",
            "episode: 500 \tfinetune acc:50.000000 \t\ttest acc:47.916667\n",
            "episode: 550 \tfinetune acc:57.500000 \t\ttest acc:58.333333\n",
            "episode: 600 \tfinetune acc:50.000000 \t\ttest acc:62.500000\n",
            "episode: 650 \tfinetune acc:51.250000 \t\ttest acc:54.166667\n",
            "episode: 700 \tfinetune acc:57.500000 \t\ttest acc:50.000000\n",
            "episode: 750 \tfinetune acc:61.250000 \t\ttest acc:58.333333\n",
            "episode: 800 \tfinetune acc:62.500000 \t\ttest acc:60.416667\n",
            "episode: 850 \tfinetune acc:53.750000 \t\ttest acc:64.583333\n",
            "episode: 900 \tfinetune acc:56.250000 \t\ttest acc:47.916667\n",
            "episode: 950 \tfinetune acc:56.250000 \t\ttest acc:70.833333\n",
            "episode: 1000 \tfinetune acc:57.500000 \t\ttest acc:72.916667\n",
            "episode: 1050 \tfinetune acc:57.500000 \t\ttest acc:58.333333\n",
            "episode: 1100 \tfinetune acc:55.000000 \t\ttest acc:68.750000\n",
            "episode: 1150 \tfinetune acc:72.500000 \t\ttest acc:60.416667\n",
            "episode: 1200 \tfinetune acc:61.250000 \t\ttest acc:56.250000\n",
            "episode: 1250 \tfinetune acc:58.750000 \t\ttest acc:56.250000\n",
            "episode: 1300 \tfinetune acc:58.750000 \t\ttest acc:70.833333\n",
            "episode: 1350 \tfinetune acc:65.000000 \t\ttest acc:62.500000\n",
            "episode: 1400 \tfinetune acc:58.750000 \t\ttest acc:58.333333\n",
            "episode: 1450 \tfinetune acc:66.250000 \t\ttest acc:54.166667\n",
            "episode: 1500 \tfinetune acc:56.250000 \t\ttest acc:72.916667\n",
            "episode: 1550 \tfinetune acc:51.250000 \t\ttest acc:77.083333\n",
            "episode: 1600 \tfinetune acc:58.750000 \t\ttest acc:54.166667\n",
            "episode: 1650 \tfinetune acc:62.500000 \t\ttest acc:62.500000\n",
            "episode: 1700 \tfinetune acc:56.250000 \t\ttest acc:64.583333\n",
            "episode: 1750 \tfinetune acc:55.000000 \t\ttest acc:54.166667\n",
            "episode: 1800 \tfinetune acc:73.750000 \t\ttest acc:66.666667\n",
            "episode: 1850 \tfinetune acc:60.000000 \t\ttest acc:56.250000\n",
            "episode: 1900 \tfinetune acc:62.500000 \t\ttest acc:68.750000\n",
            "episode: 1950 \tfinetune acc:62.500000 \t\ttest acc:66.666667\n",
            "episode: 2000 \tfinetune acc:63.750000 \t\ttest acc:75.000000\n",
            "episode: 2050 \tfinetune acc:52.500000 \t\ttest acc:66.666667\n",
            "episode: 2100 \tfinetune acc:58.750000 \t\ttest acc:68.750000\n",
            "episode: 2150 \tfinetune acc:61.250000 \t\ttest acc:58.333333\n",
            "episode: 2200 \tfinetune acc:55.000000 \t\ttest acc:66.666667\n",
            "episode: 2250 \tfinetune acc:46.250000 \t\ttest acc:66.666667\n",
            "episode: 2300 \tfinetune acc:57.500000 \t\ttest acc:50.000000\n",
            "episode: 2350 \tfinetune acc:65.000000 \t\ttest acc:60.416667\n",
            "episode: 2400 \tfinetune acc:58.750000 \t\ttest acc:56.250000\n",
            "episode: 2450 \tfinetune acc:56.250000 \t\ttest acc:68.750000\n",
            "episode: 2500 \tfinetune acc:67.500000 \t\ttest acc:50.000000\n",
            "episode: 2550 \tfinetune acc:67.500000 \t\ttest acc:64.583333\n",
            "episode: 2600 \tfinetune acc:61.250000 \t\ttest acc:47.916667\n",
            "episode: 2650 \tfinetune acc:47.500000 \t\ttest acc:58.333333\n",
            "episode: 2700 \tfinetune acc:66.250000 \t\ttest acc:60.416667\n",
            "episode: 2750 \tfinetune acc:58.750000 \t\ttest acc:60.416667\n",
            "episode: 2800 \tfinetune acc:63.750000 \t\ttest acc:62.500000\n",
            "episode: 2850 \tfinetune acc:58.750000 \t\ttest acc:64.583333\n",
            "episode: 2900 \tfinetune acc:60.000000 \t\ttest acc:62.500000\n",
            "episode: 2950 \tfinetune acc:60.000000 \t\ttest acc:68.750000\n",
            "episode: 3000 \tfinetune acc:67.500000 \t\ttest acc:52.083333\n",
            "episode: 3050 \tfinetune acc:66.250000 \t\ttest acc:70.833333\n",
            "episode: 3100 \tfinetune acc:67.500000 \t\ttest acc:68.750000\n",
            "episode: 3150 \tfinetune acc:66.250000 \t\ttest acc:64.583333\n",
            "episode: 3200 \tfinetune acc:66.250000 \t\ttest acc:66.666667\n",
            "episode: 3250 \tfinetune acc:66.250000 \t\ttest acc:60.416667\n",
            "episode: 3300 \tfinetune acc:66.250000 \t\ttest acc:62.500000\n",
            "episode: 3350 \tfinetune acc:68.750000 \t\ttest acc:60.416667\n",
            "episode: 3400 \tfinetune acc:61.250000 \t\ttest acc:64.583333\n",
            "episode: 3450 \tfinetune acc:71.250000 \t\ttest acc:60.416667\n",
            "episode: 3500 \tfinetune acc:70.000000 \t\ttest acc:62.500000\n",
            "episode: 3550 \tfinetune acc:71.250000 \t\ttest acc:54.166667\n",
            "episode: 3600 \tfinetune acc:56.250000 \t\ttest acc:52.083333\n",
            "episode: 3650 \tfinetune acc:60.000000 \t\ttest acc:72.916667\n",
            "episode: 3700 \tfinetune acc:65.000000 \t\ttest acc:62.500000\n",
            "episode: 3750 \tfinetune acc:60.000000 \t\ttest acc:64.583333\n",
            "episode: 3800 \tfinetune acc:71.250000 \t\ttest acc:64.583333\n",
            "episode: 3850 \tfinetune acc:67.500000 \t\ttest acc:68.750000\n",
            "episode: 3900 \tfinetune acc:71.250000 \t\ttest acc:60.416667\n",
            "episode: 3950 \tfinetune acc:67.500000 \t\ttest acc:58.333333\n",
            "episode: 4000 \tfinetune acc:60.000000 \t\ttest acc:62.500000\n",
            "episode: 4050 \tfinetune acc:76.250000 \t\ttest acc:54.166667\n",
            "episode: 4100 \tfinetune acc:61.250000 \t\ttest acc:62.500000\n",
            "episode: 4150 \tfinetune acc:57.500000 \t\ttest acc:58.333333\n",
            "episode: 4200 \tfinetune acc:62.500000 \t\ttest acc:56.250000\n",
            "episode: 4250 \tfinetune acc:58.750000 \t\ttest acc:64.583333\n",
            "episode: 4300 \tfinetune acc:55.000000 \t\ttest acc:58.333333\n",
            "episode: 4350 \tfinetune acc:70.000000 \t\ttest acc:60.416667\n",
            "episode: 4400 \tfinetune acc:63.750000 \t\ttest acc:68.750000\n",
            "episode: 4450 \tfinetune acc:52.500000 \t\ttest acc:54.166667\n",
            "episode: 4500 \tfinetune acc:66.250000 \t\ttest acc:56.250000\n",
            "episode: 4550 \tfinetune acc:70.000000 \t\ttest acc:52.083333\n",
            "episode: 4600 \tfinetune acc:71.250000 \t\ttest acc:64.583333\n",
            "episode: 4650 \tfinetune acc:63.750000 \t\ttest acc:62.500000\n",
            "episode: 4700 \tfinetune acc:62.500000 \t\ttest acc:56.250000\n",
            "episode: 4750 \tfinetune acc:71.250000 \t\ttest acc:66.666667\n",
            "episode: 4800 \tfinetune acc:58.750000 \t\ttest acc:66.666667\n",
            "episode: 4850 \tfinetune acc:66.250000 \t\ttest acc:64.583333\n",
            "episode: 4900 \tfinetune acc:66.250000 \t\ttest acc:70.833333\n",
            "episode: 4950 \tfinetune acc:60.000000 \t\ttest acc:60.416667\n",
            "episode: 5000 \tfinetune acc:61.250000 \t\ttest acc:57.812500\n",
            "episode: 5050 \tfinetune acc:61.250000 \t\ttest acc:67.187500\n",
            "episode: 5100 \tfinetune acc:72.500000 \t\ttest acc:57.812500\n",
            "episode: 5150 \tfinetune acc:58.750000 \t\ttest acc:62.500000\n",
            "episode: 5200 \tfinetune acc:70.000000 \t\ttest acc:59.375000\n",
            "episode: 5250 \tfinetune acc:68.750000 \t\ttest acc:54.687500\n",
            "episode: 5300 \tfinetune acc:72.500000 \t\ttest acc:57.812500\n",
            "episode: 5350 \tfinetune acc:65.000000 \t\ttest acc:56.250000\n",
            "episode: 5400 \tfinetune acc:65.000000 \t\ttest acc:57.812500\n",
            "episode: 5450 \tfinetune acc:62.500000 \t\ttest acc:64.062500\n",
            "episode: 5500 \tfinetune acc:70.000000 \t\ttest acc:62.500000\n",
            "episode: 5550 \tfinetune acc:67.500000 \t\ttest acc:62.500000\n",
            "episode: 5600 \tfinetune acc:61.250000 \t\ttest acc:59.375000\n",
            "episode: 5650 \tfinetune acc:72.500000 \t\ttest acc:50.000000\n",
            "episode: 5700 \tfinetune acc:70.000000 \t\ttest acc:62.500000\n",
            "episode: 5750 \tfinetune acc:68.750000 \t\ttest acc:68.750000\n",
            "episode: 5800 \tfinetune acc:55.000000 \t\ttest acc:70.312500\n",
            "episode: 5850 \tfinetune acc:61.250000 \t\ttest acc:62.500000\n",
            "episode: 5900 \tfinetune acc:61.250000 \t\ttest acc:71.875000\n",
            "episode: 5950 \tfinetune acc:58.750000 \t\ttest acc:53.125000\n",
            "episode: 6000 \tfinetune acc:55.000000 \t\ttest acc:73.437500\n",
            "episode: 6050 \tfinetune acc:71.250000 \t\ttest acc:64.062500\n",
            "episode: 6100 \tfinetune acc:68.750000 \t\ttest acc:56.250000\n",
            "episode: 6150 \tfinetune acc:67.500000 \t\ttest acc:57.812500\n",
            "episode: 6200 \tfinetune acc:60.000000 \t\ttest acc:50.000000\n",
            "episode: 6250 \tfinetune acc:72.500000 \t\ttest acc:51.562500\n",
            "episode: 6300 \tfinetune acc:60.000000 \t\ttest acc:64.062500\n",
            "episode: 6350 \tfinetune acc:67.500000 \t\ttest acc:57.812500\n",
            "episode: 6400 \tfinetune acc:63.750000 \t\ttest acc:60.937500\n",
            "episode: 6450 \tfinetune acc:76.250000 \t\ttest acc:45.312500\n",
            "episode: 6500 \tfinetune acc:71.250000 \t\ttest acc:54.687500\n",
            "episode: 6550 \tfinetune acc:63.750000 \t\ttest acc:70.312500\n",
            "episode: 6600 \tfinetune acc:65.000000 \t\ttest acc:50.000000\n",
            "episode: 6650 \tfinetune acc:58.750000 \t\ttest acc:57.812500\n",
            "episode: 6700 \tfinetune acc:72.500000 \t\ttest acc:65.625000\n",
            "episode: 6750 \tfinetune acc:73.750000 \t\ttest acc:56.250000\n",
            "episode: 6800 \tfinetune acc:61.250000 \t\ttest acc:56.250000\n",
            "episode: 6850 \tfinetune acc:61.250000 \t\ttest acc:56.250000\n",
            "episode: 6900 \tfinetune acc:65.000000 \t\ttest acc:59.375000\n",
            "episode: 6950 \tfinetune acc:55.000000 \t\ttest acc:62.500000\n",
            "episode: 7000 \tfinetune acc:62.500000 \t\ttest acc:60.937500\n",
            "episode: 7050 \tfinetune acc:63.750000 \t\ttest acc:46.875000\n",
            "episode: 7100 \tfinetune acc:56.250000 \t\ttest acc:59.375000\n",
            "episode: 7150 \tfinetune acc:58.750000 \t\ttest acc:59.375000\n",
            "episode: 7200 \tfinetune acc:67.500000 \t\ttest acc:57.812500\n",
            "episode: 7250 \tfinetune acc:58.750000 \t\ttest acc:64.062500\n",
            "episode: 7300 \tfinetune acc:61.250000 \t\ttest acc:59.375000\n",
            "episode: 7350 \tfinetune acc:76.250000 \t\ttest acc:57.812500\n",
            "episode: 7400 \tfinetune acc:56.250000 \t\ttest acc:60.937500\n",
            "episode: 7450 \tfinetune acc:55.000000 \t\ttest acc:57.812500\n",
            "episode: 7500 \tfinetune acc:67.500000 \t\ttest acc:67.187500\n",
            "episode: 7550 \tfinetune acc:53.750000 \t\ttest acc:65.625000\n",
            "episode: 7600 \tfinetune acc:66.250000 \t\ttest acc:56.250000\n",
            "episode: 7650 \tfinetune acc:66.250000 \t\ttest acc:67.187500\n",
            "episode: 7700 \tfinetune acc:71.250000 \t\ttest acc:56.250000\n",
            "episode: 7750 \tfinetune acc:68.750000 \t\ttest acc:65.625000\n",
            "episode: 7800 \tfinetune acc:65.000000 \t\ttest acc:54.687500\n",
            "episode: 7850 \tfinetune acc:56.250000 \t\ttest acc:57.812500\n",
            "episode: 7900 \tfinetune acc:66.250000 \t\ttest acc:64.062500\n",
            "episode: 7950 \tfinetune acc:65.000000 \t\ttest acc:57.812500\n",
            "episode: 8000 \tfinetune acc:60.000000 \t\ttest acc:57.812500\n",
            "episode: 8050 \tfinetune acc:63.750000 \t\ttest acc:75.000000\n",
            "episode: 8100 \tfinetune acc:61.250000 \t\ttest acc:64.062500\n",
            "episode: 8150 \tfinetune acc:58.750000 \t\ttest acc:57.812500\n",
            "episode: 8200 \tfinetune acc:60.000000 \t\ttest acc:60.937500\n",
            "episode: 8250 \tfinetune acc:68.750000 \t\ttest acc:37.500000\n",
            "episode: 8300 \tfinetune acc:66.250000 \t\ttest acc:67.187500\n",
            "episode: 8350 \tfinetune acc:71.250000 \t\ttest acc:62.500000\n",
            "episode: 8400 \tfinetune acc:51.250000 \t\ttest acc:59.375000\n",
            "episode: 8450 \tfinetune acc:72.500000 \t\ttest acc:65.625000\n",
            "episode: 8500 \tfinetune acc:68.750000 \t\ttest acc:62.500000\n",
            "episode: 8550 \tfinetune acc:56.250000 \t\ttest acc:60.937500\n",
            "episode: 8600 \tfinetune acc:73.750000 \t\ttest acc:50.000000\n",
            "episode: 8650 \tfinetune acc:57.500000 \t\ttest acc:56.250000\n",
            "episode: 8700 \tfinetune acc:72.500000 \t\ttest acc:62.500000\n",
            "episode: 8750 \tfinetune acc:68.750000 \t\ttest acc:62.500000\n",
            "episode: 8800 \tfinetune acc:71.250000 \t\ttest acc:62.500000\n",
            "episode: 8850 \tfinetune acc:61.250000 \t\ttest acc:64.062500\n",
            "episode: 8900 \tfinetune acc:60.000000 \t\ttest acc:67.187500\n",
            "episode: 8950 \tfinetune acc:66.250000 \t\ttest acc:57.812500\n",
            "episode: 9000 \tfinetune acc:67.500000 \t\ttest acc:60.937500\n",
            "episode: 9050 \tfinetune acc:76.250000 \t\ttest acc:59.375000\n",
            "episode: 9100 \tfinetune acc:75.000000 \t\ttest acc:53.125000\n",
            "episode: 9150 \tfinetune acc:67.500000 \t\ttest acc:53.125000\n",
            "episode: 9200 \tfinetune acc:71.250000 \t\ttest acc:59.375000\n",
            "episode: 9250 \tfinetune acc:81.250000 \t\ttest acc:54.687500\n",
            "episode: 9300 \tfinetune acc:71.250000 \t\ttest acc:60.937500\n",
            "episode: 9350 \tfinetune acc:73.750000 \t\ttest acc:54.687500\n",
            "episode: 9400 \tfinetune acc:77.500000 \t\ttest acc:60.937500\n",
            "episode: 9450 \tfinetune acc:72.500000 \t\ttest acc:57.812500\n",
            "episode: 9500 \tfinetune acc:60.000000 \t\ttest acc:64.062500\n",
            "episode: 9550 \tfinetune acc:72.500000 \t\ttest acc:64.062500\n",
            "episode: 9600 \tfinetune acc:57.500000 \t\ttest acc:60.937500\n",
            "episode: 9650 \tfinetune acc:67.500000 \t\ttest acc:64.062500\n",
            "episode: 9700 \tfinetune acc:71.250000 \t\ttest acc:64.062500\n",
            "episode: 9750 \tfinetune acc:66.250000 \t\ttest acc:59.375000\n",
            "episode: 9800 \tfinetune acc:63.750000 \t\ttest acc:53.125000\n",
            "episode: 9850 \tfinetune acc:57.500000 \t\ttest acc:53.125000\n",
            "episode: 9900 \tfinetune acc:70.000000 \t\ttest acc:65.625000\n",
            "episode: 9950 \tfinetune acc:60.000000 \t\ttest acc:54.687500\n",
            "episode: 10000 \tfinetune acc:72.500000 \t\ttest acc:66.250000\n",
            "episode: 10050 \tfinetune acc:71.250000 \t\ttest acc:66.250000\n",
            "episode: 10100 \tfinetune acc:68.750000 \t\ttest acc:63.750000\n",
            "episode: 10150 \tfinetune acc:81.250000 \t\ttest acc:58.750000\n",
            "episode: 10200 \tfinetune acc:83.750000 \t\ttest acc:60.000000\n",
            "episode: 10250 \tfinetune acc:72.500000 \t\ttest acc:61.250000\n",
            "episode: 10300 \tfinetune acc:70.000000 \t\ttest acc:56.250000\n",
            "episode: 10350 \tfinetune acc:61.250000 \t\ttest acc:68.750000\n",
            "episode: 10400 \tfinetune acc:67.500000 \t\ttest acc:66.250000\n",
            "episode: 10450 \tfinetune acc:70.000000 \t\ttest acc:62.500000\n",
            "episode: 10500 \tfinetune acc:66.250000 \t\ttest acc:55.000000\n",
            "episode: 10550 \tfinetune acc:76.250000 \t\ttest acc:55.000000\n",
            "episode: 10600 \tfinetune acc:67.500000 \t\ttest acc:57.500000\n",
            "episode: 10650 \tfinetune acc:63.750000 \t\ttest acc:61.250000\n",
            "episode: 10700 \tfinetune acc:68.750000 \t\ttest acc:65.000000\n",
            "episode: 10750 \tfinetune acc:58.750000 \t\ttest acc:62.500000\n",
            "episode: 10800 \tfinetune acc:75.000000 \t\ttest acc:58.750000\n",
            "episode: 10850 \tfinetune acc:65.000000 \t\ttest acc:60.000000\n",
            "episode: 10900 \tfinetune acc:67.500000 \t\ttest acc:57.500000\n",
            "episode: 10950 \tfinetune acc:78.750000 \t\ttest acc:55.000000\n",
            "episode: 11000 \tfinetune acc:71.250000 \t\ttest acc:58.750000\n",
            "episode: 11050 \tfinetune acc:71.250000 \t\ttest acc:55.000000\n",
            "episode: 11100 \tfinetune acc:68.750000 \t\ttest acc:71.250000\n",
            "episode: 11150 \tfinetune acc:72.500000 \t\ttest acc:60.000000\n",
            "episode: 11200 \tfinetune acc:67.500000 \t\ttest acc:60.000000\n",
            "episode: 11250 \tfinetune acc:60.000000 \t\ttest acc:61.250000\n",
            "episode: 11300 \tfinetune acc:62.500000 \t\ttest acc:75.000000\n",
            "episode: 11350 \tfinetune acc:60.000000 \t\ttest acc:67.500000\n",
            "episode: 11400 \tfinetune acc:70.000000 \t\ttest acc:57.500000\n",
            "episode: 11450 \tfinetune acc:73.750000 \t\ttest acc:57.500000\n",
            "episode: 11500 \tfinetune acc:67.500000 \t\ttest acc:51.250000\n",
            "episode: 11550 \tfinetune acc:72.500000 \t\ttest acc:68.750000\n",
            "episode: 11600 \tfinetune acc:67.500000 \t\ttest acc:57.500000\n",
            "episode: 11650 \tfinetune acc:68.750000 \t\ttest acc:67.500000\n",
            "episode: 11700 \tfinetune acc:53.750000 \t\ttest acc:55.000000\n",
            "episode: 11750 \tfinetune acc:58.750000 \t\ttest acc:63.750000\n",
            "episode: 11800 \tfinetune acc:72.500000 \t\ttest acc:61.250000\n",
            "episode: 11850 \tfinetune acc:71.250000 \t\ttest acc:55.000000\n",
            "episode: 11900 \tfinetune acc:61.250000 \t\ttest acc:60.000000\n",
            "episode: 11950 \tfinetune acc:68.750000 \t\ttest acc:61.250000\n",
            "episode: 12000 \tfinetune acc:62.500000 \t\ttest acc:58.750000\n",
            "episode: 12050 \tfinetune acc:68.750000 \t\ttest acc:51.250000\n",
            "episode: 12100 \tfinetune acc:73.750000 \t\ttest acc:60.000000\n",
            "episode: 12150 \tfinetune acc:61.250000 \t\ttest acc:57.500000\n",
            "episode: 12200 \tfinetune acc:65.000000 \t\ttest acc:63.750000\n",
            "episode: 12250 \tfinetune acc:76.250000 \t\ttest acc:66.250000\n",
            "episode: 12300 \tfinetune acc:66.250000 \t\ttest acc:61.250000\n",
            "episode: 12350 \tfinetune acc:77.500000 \t\ttest acc:60.000000\n",
            "episode: 12400 \tfinetune acc:75.000000 \t\ttest acc:62.500000\n",
            "episode: 12450 \tfinetune acc:68.750000 \t\ttest acc:67.500000\n",
            "episode: 12500 \tfinetune acc:66.250000 \t\ttest acc:55.000000\n",
            "episode: 12550 \tfinetune acc:75.000000 \t\ttest acc:70.000000\n",
            "episode: 12600 \tfinetune acc:68.750000 \t\ttest acc:57.500000\n",
            "episode: 12650 \tfinetune acc:73.750000 \t\ttest acc:58.750000\n",
            "episode: 12700 \tfinetune acc:75.000000 \t\ttest acc:60.000000\n",
            "episode: 12750 \tfinetune acc:72.500000 \t\ttest acc:62.500000\n",
            "episode: 12800 \tfinetune acc:77.500000 \t\ttest acc:71.250000\n",
            "episode: 12850 \tfinetune acc:67.500000 \t\ttest acc:66.250000\n",
            "episode: 12900 \tfinetune acc:65.000000 \t\ttest acc:52.500000\n",
            "episode: 12950 \tfinetune acc:72.500000 \t\ttest acc:62.500000\n",
            "episode: 13000 \tfinetune acc:72.500000 \t\ttest acc:63.750000\n",
            "episode: 13050 \tfinetune acc:76.250000 \t\ttest acc:57.500000\n",
            "episode: 13100 \tfinetune acc:66.250000 \t\ttest acc:51.250000\n",
            "episode: 13150 \tfinetune acc:70.000000 \t\ttest acc:61.250000\n",
            "episode: 13200 \tfinetune acc:67.500000 \t\ttest acc:65.000000\n",
            "episode: 13250 \tfinetune acc:68.750000 \t\ttest acc:56.250000\n",
            "episode: 13300 \tfinetune acc:72.500000 \t\ttest acc:58.750000\n",
            "episode: 13350 \tfinetune acc:71.250000 \t\ttest acc:60.000000\n",
            "episode: 13400 \tfinetune acc:72.500000 \t\ttest acc:57.500000\n",
            "episode: 13450 \tfinetune acc:67.500000 \t\ttest acc:70.000000\n",
            "episode: 13500 \tfinetune acc:62.500000 \t\ttest acc:56.250000\n",
            "episode: 13550 \tfinetune acc:76.250000 \t\ttest acc:52.500000\n",
            "episode: 13600 \tfinetune acc:65.000000 \t\ttest acc:63.750000\n",
            "episode: 13650 \tfinetune acc:60.000000 \t\ttest acc:63.750000\n",
            "episode: 13700 \tfinetune acc:76.250000 \t\ttest acc:61.250000\n",
            "episode: 13750 \tfinetune acc:76.250000 \t\ttest acc:53.750000\n",
            "episode: 13800 \tfinetune acc:68.750000 \t\ttest acc:56.250000\n",
            "episode: 13850 \tfinetune acc:67.500000 \t\ttest acc:67.500000\n",
            "episode: 13900 \tfinetune acc:67.500000 \t\ttest acc:66.250000\n",
            "episode: 13950 \tfinetune acc:70.000000 \t\ttest acc:58.750000\n",
            "episode: 14000 \tfinetune acc:77.500000 \t\ttest acc:62.500000\n",
            "episode: 14050 \tfinetune acc:67.500000 \t\ttest acc:63.750000\n",
            "episode: 14100 \tfinetune acc:68.750000 \t\ttest acc:60.000000\n",
            "episode: 14150 \tfinetune acc:63.750000 \t\ttest acc:61.250000\n",
            "episode: 14200 \tfinetune acc:62.500000 \t\ttest acc:67.500000\n",
            "episode: 14250 \tfinetune acc:71.250000 \t\ttest acc:61.250000\n",
            "episode: 14300 \tfinetune acc:72.500000 \t\ttest acc:60.000000\n",
            "episode: 14350 \tfinetune acc:63.750000 \t\ttest acc:56.250000\n",
            "episode: 14400 \tfinetune acc:80.000000 \t\ttest acc:67.500000\n",
            "episode: 14450 \tfinetune acc:61.250000 \t\ttest acc:62.500000\n",
            "episode: 14500 \tfinetune acc:66.250000 \t\ttest acc:58.750000\n",
            "episode: 14550 \tfinetune acc:63.750000 \t\ttest acc:68.750000\n",
            "episode: 14600 \tfinetune acc:72.500000 \t\ttest acc:58.750000\n",
            "episode: 14650 \tfinetune acc:75.000000 \t\ttest acc:62.500000\n",
            "episode: 14700 \tfinetune acc:66.250000 \t\ttest acc:63.750000\n",
            "episode: 14750 \tfinetune acc:73.750000 \t\ttest acc:58.750000\n",
            "episode: 14800 \tfinetune acc:77.500000 \t\ttest acc:57.500000\n",
            "episode: 14850 \tfinetune acc:66.250000 \t\ttest acc:57.500000\n",
            "episode: 14900 \tfinetune acc:63.750000 \t\ttest acc:65.000000\n",
            "episode: 14950 \tfinetune acc:70.000000 \t\ttest acc:61.250000\n",
            "episode: 15000 \tfinetune acc:67.500000 \t\ttest acc:60.416667\n",
            "episode: 15050 \tfinetune acc:67.500000 \t\ttest acc:60.416667\n",
            "episode: 15100 \tfinetune acc:73.750000 \t\ttest acc:71.875000\n",
            "episode: 15150 \tfinetune acc:67.500000 \t\ttest acc:68.750000\n",
            "episode: 15200 \tfinetune acc:72.500000 \t\ttest acc:55.208333\n",
            "episode: 15250 \tfinetune acc:57.500000 \t\ttest acc:58.333333\n",
            "episode: 15300 \tfinetune acc:73.750000 \t\ttest acc:59.375000\n",
            "episode: 15350 \tfinetune acc:71.250000 \t\ttest acc:55.208333\n",
            "episode: 15400 \tfinetune acc:63.750000 \t\ttest acc:62.500000\n",
            "episode: 15450 \tfinetune acc:75.000000 \t\ttest acc:62.500000\n",
            "episode: 15500 \tfinetune acc:75.000000 \t\ttest acc:62.500000\n",
            "episode: 15550 \tfinetune acc:68.750000 \t\ttest acc:60.416667\n",
            "episode: 15600 \tfinetune acc:70.000000 \t\ttest acc:66.666667\n",
            "episode: 15650 \tfinetune acc:66.250000 \t\ttest acc:50.000000\n",
            "episode: 15700 \tfinetune acc:76.250000 \t\ttest acc:59.375000\n",
            "episode: 15750 \tfinetune acc:62.500000 \t\ttest acc:65.625000\n",
            "episode: 15800 \tfinetune acc:70.000000 \t\ttest acc:57.291667\n",
            "episode: 15850 \tfinetune acc:72.500000 \t\ttest acc:57.291667\n",
            "episode: 15900 \tfinetune acc:65.000000 \t\ttest acc:58.333333\n",
            "episode: 15950 \tfinetune acc:68.750000 \t\ttest acc:63.541667\n",
            "episode: 16000 \tfinetune acc:68.750000 \t\ttest acc:62.500000\n",
            "episode: 16050 \tfinetune acc:71.250000 \t\ttest acc:59.375000\n",
            "episode: 16100 \tfinetune acc:78.750000 \t\ttest acc:57.291667\n",
            "episode: 16150 \tfinetune acc:63.750000 \t\ttest acc:65.625000\n",
            "episode: 16200 \tfinetune acc:67.500000 \t\ttest acc:68.750000\n",
            "episode: 16250 \tfinetune acc:70.000000 \t\ttest acc:72.916667\n",
            "episode: 16300 \tfinetune acc:76.250000 \t\ttest acc:66.666667\n",
            "episode: 16350 \tfinetune acc:76.250000 \t\ttest acc:72.916667\n",
            "episode: 16400 \tfinetune acc:72.500000 \t\ttest acc:60.416667\n",
            "episode: 16450 \tfinetune acc:70.000000 \t\ttest acc:64.583333\n",
            "episode: 16500 \tfinetune acc:65.000000 \t\ttest acc:63.541667\n",
            "episode: 16550 \tfinetune acc:72.500000 \t\ttest acc:63.541667\n",
            "episode: 16600 \tfinetune acc:71.250000 \t\ttest acc:64.583333\n",
            "episode: 16650 \tfinetune acc:83.750000 \t\ttest acc:63.541667\n",
            "episode: 16700 \tfinetune acc:75.000000 \t\ttest acc:61.458333\n",
            "episode: 16750 \tfinetune acc:63.750000 \t\ttest acc:62.500000\n",
            "episode: 16800 \tfinetune acc:72.500000 \t\ttest acc:64.583333\n",
            "episode: 16850 \tfinetune acc:65.000000 \t\ttest acc:64.583333\n",
            "episode: 16900 \tfinetune acc:58.750000 \t\ttest acc:73.958333\n",
            "episode: 16950 \tfinetune acc:68.750000 \t\ttest acc:60.416667\n",
            "episode: 17000 \tfinetune acc:72.500000 \t\ttest acc:63.541667\n",
            "episode: 17050 \tfinetune acc:81.250000 \t\ttest acc:72.916667\n",
            "episode: 17100 \tfinetune acc:71.250000 \t\ttest acc:58.333333\n",
            "episode: 17150 \tfinetune acc:63.750000 \t\ttest acc:61.458333\n",
            "episode: 17200 \tfinetune acc:73.750000 \t\ttest acc:69.791667\n",
            "episode: 17250 \tfinetune acc:66.250000 \t\ttest acc:54.166667\n",
            "episode: 17300 \tfinetune acc:75.000000 \t\ttest acc:61.458333\n",
            "episode: 17350 \tfinetune acc:66.250000 \t\ttest acc:58.333333\n",
            "episode: 17400 \tfinetune acc:58.750000 \t\ttest acc:67.708333\n",
            "episode: 17450 \tfinetune acc:73.750000 \t\ttest acc:53.125000\n",
            "episode: 17500 \tfinetune acc:58.750000 \t\ttest acc:63.541667\n",
            "episode: 17550 \tfinetune acc:76.250000 \t\ttest acc:65.625000\n",
            "episode: 17600 \tfinetune acc:71.250000 \t\ttest acc:61.458333\n",
            "episode: 17650 \tfinetune acc:71.250000 \t\ttest acc:64.583333\n",
            "episode: 17700 \tfinetune acc:70.000000 \t\ttest acc:66.666667\n",
            "episode: 17750 \tfinetune acc:70.000000 \t\ttest acc:58.333333\n",
            "episode: 17800 \tfinetune acc:68.750000 \t\ttest acc:58.333333\n",
            "episode: 17850 \tfinetune acc:76.250000 \t\ttest acc:63.541667\n",
            "episode: 17900 \tfinetune acc:71.250000 \t\ttest acc:59.375000\n",
            "episode: 17950 \tfinetune acc:77.500000 \t\ttest acc:65.625000\n",
            "episode: 18000 \tfinetune acc:76.250000 \t\ttest acc:64.583333\n",
            "episode: 18050 \tfinetune acc:73.750000 \t\ttest acc:61.458333\n",
            "episode: 18100 \tfinetune acc:65.000000 \t\ttest acc:65.625000\n",
            "episode: 18150 \tfinetune acc:71.250000 \t\ttest acc:66.666667\n",
            "episode: 18200 \tfinetune acc:63.750000 \t\ttest acc:65.625000\n",
            "episode: 18250 \tfinetune acc:66.250000 \t\ttest acc:69.791667\n",
            "episode: 18300 \tfinetune acc:73.750000 \t\ttest acc:61.458333\n",
            "episode: 18350 \tfinetune acc:71.250000 \t\ttest acc:58.333333\n",
            "episode: 18400 \tfinetune acc:77.500000 \t\ttest acc:58.333333\n",
            "episode: 18450 \tfinetune acc:68.750000 \t\ttest acc:61.458333\n",
            "episode: 18500 \tfinetune acc:57.500000 \t\ttest acc:54.166667\n",
            "episode: 18550 \tfinetune acc:72.500000 \t\ttest acc:66.666667\n",
            "episode: 18600 \tfinetune acc:60.000000 \t\ttest acc:63.541667\n",
            "episode: 18650 \tfinetune acc:80.000000 \t\ttest acc:57.291667\n",
            "episode: 18700 \tfinetune acc:76.250000 \t\ttest acc:56.250000\n",
            "episode: 18750 \tfinetune acc:66.250000 \t\ttest acc:66.666667\n",
            "episode: 18800 \tfinetune acc:72.500000 \t\ttest acc:60.416667\n",
            "episode: 18850 \tfinetune acc:67.500000 \t\ttest acc:58.333333\n",
            "episode: 18900 \tfinetune acc:66.250000 \t\ttest acc:64.583333\n",
            "episode: 18950 \tfinetune acc:75.000000 \t\ttest acc:63.541667\n",
            "episode: 19000 \tfinetune acc:76.250000 \t\ttest acc:58.333333\n",
            "episode: 19050 \tfinetune acc:66.250000 \t\ttest acc:55.208333\n",
            "episode: 19100 \tfinetune acc:90.000000 \t\ttest acc:61.458333\n",
            "episode: 19150 \tfinetune acc:66.250000 \t\ttest acc:59.375000\n",
            "episode: 19200 \tfinetune acc:77.500000 \t\ttest acc:63.541667\n",
            "episode: 19250 \tfinetune acc:68.750000 \t\ttest acc:67.708333\n",
            "episode: 19300 \tfinetune acc:75.000000 \t\ttest acc:55.208333\n",
            "episode: 19350 \tfinetune acc:66.250000 \t\ttest acc:64.583333\n",
            "episode: 19400 \tfinetune acc:66.250000 \t\ttest acc:59.375000\n",
            "episode: 19450 \tfinetune acc:70.000000 \t\ttest acc:69.791667\n",
            "episode: 19500 \tfinetune acc:66.250000 \t\ttest acc:65.625000\n",
            "episode: 19550 \tfinetune acc:70.000000 \t\ttest acc:63.541667\n",
            "episode: 19600 \tfinetune acc:65.000000 \t\ttest acc:61.458333\n",
            "episode: 19650 \tfinetune acc:67.500000 \t\ttest acc:58.333333\n",
            "episode: 19700 \tfinetune acc:76.250000 \t\ttest acc:63.541667\n",
            "episode: 19750 \tfinetune acc:68.750000 \t\ttest acc:61.458333\n",
            "episode: 19800 \tfinetune acc:75.000000 \t\ttest acc:53.125000\n",
            "episode: 19850 \tfinetune acc:75.000000 \t\ttest acc:64.583333\n",
            "episode: 19900 \tfinetune acc:68.750000 \t\ttest acc:66.666667\n",
            "episode: 19950 \tfinetune acc:75.000000 \t\ttest acc:63.541667\n",
            "episode: 20000 \tfinetune acc:77.500000 \t\ttest acc:54.464286\n",
            "episode: 20050 \tfinetune acc:72.500000 \t\ttest acc:57.142857\n",
            "episode: 20100 \tfinetune acc:68.750000 \t\ttest acc:65.178571\n",
            "episode: 20150 \tfinetune acc:67.500000 \t\ttest acc:54.464286\n",
            "episode: 20200 \tfinetune acc:77.500000 \t\ttest acc:61.607143\n",
            "episode: 20250 \tfinetune acc:73.750000 \t\ttest acc:56.250000\n",
            "episode: 20300 \tfinetune acc:71.250000 \t\ttest acc:66.964286\n",
            "episode: 20350 \tfinetune acc:72.500000 \t\ttest acc:63.392857\n",
            "episode: 20400 \tfinetune acc:71.250000 \t\ttest acc:63.392857\n",
            "episode: 20450 \tfinetune acc:70.000000 \t\ttest acc:61.607143\n",
            "episode: 20500 \tfinetune acc:66.250000 \t\ttest acc:65.178571\n",
            "episode: 20550 \tfinetune acc:75.000000 \t\ttest acc:69.642857\n",
            "episode: 20600 \tfinetune acc:76.250000 \t\ttest acc:60.714286\n",
            "episode: 20650 \tfinetune acc:76.250000 \t\ttest acc:57.142857\n",
            "episode: 20700 \tfinetune acc:76.250000 \t\ttest acc:64.285714\n",
            "episode: 20750 \tfinetune acc:65.000000 \t\ttest acc:60.714286\n",
            "episode: 20800 \tfinetune acc:70.000000 \t\ttest acc:58.928571\n",
            "episode: 20850 \tfinetune acc:76.250000 \t\ttest acc:67.857143\n",
            "episode: 20900 \tfinetune acc:75.000000 \t\ttest acc:66.964286\n",
            "episode: 20950 \tfinetune acc:65.000000 \t\ttest acc:64.285714\n",
            "episode: 21000 \tfinetune acc:73.750000 \t\ttest acc:63.392857\n",
            "episode: 21050 \tfinetune acc:67.500000 \t\ttest acc:57.142857\n",
            "episode: 21100 \tfinetune acc:76.250000 \t\ttest acc:57.142857\n",
            "episode: 21150 \tfinetune acc:67.500000 \t\ttest acc:64.285714\n",
            "episode: 21200 \tfinetune acc:55.000000 \t\ttest acc:62.500000\n",
            "episode: 21250 \tfinetune acc:75.000000 \t\ttest acc:65.178571\n",
            "episode: 21300 \tfinetune acc:63.750000 \t\ttest acc:65.178571\n",
            "episode: 21350 \tfinetune acc:78.750000 \t\ttest acc:53.571429\n",
            "episode: 21400 \tfinetune acc:75.000000 \t\ttest acc:56.250000\n",
            "episode: 21450 \tfinetune acc:76.250000 \t\ttest acc:55.357143\n",
            "episode: 21500 \tfinetune acc:73.750000 \t\ttest acc:66.071429\n",
            "episode: 21550 \tfinetune acc:77.500000 \t\ttest acc:59.821429\n",
            "episode: 21600 \tfinetune acc:68.750000 \t\ttest acc:67.857143\n",
            "episode: 21650 \tfinetune acc:70.000000 \t\ttest acc:64.285714\n",
            "episode: 21700 \tfinetune acc:62.500000 \t\ttest acc:60.714286\n",
            "episode: 21750 \tfinetune acc:81.250000 \t\ttest acc:60.714286\n",
            "episode: 21800 \tfinetune acc:76.250000 \t\ttest acc:58.035714\n",
            "episode: 21850 \tfinetune acc:70.000000 \t\ttest acc:61.607143\n",
            "episode: 21900 \tfinetune acc:75.000000 \t\ttest acc:61.607143\n",
            "episode: 21950 \tfinetune acc:68.750000 \t\ttest acc:61.607143\n",
            "episode: 22000 \tfinetune acc:72.500000 \t\ttest acc:61.607143\n",
            "episode: 22050 \tfinetune acc:60.000000 \t\ttest acc:58.035714\n",
            "episode: 22100 \tfinetune acc:73.750000 \t\ttest acc:70.535714\n",
            "episode: 22150 \tfinetune acc:62.500000 \t\ttest acc:56.250000\n",
            "episode: 22200 \tfinetune acc:77.500000 \t\ttest acc:57.142857\n",
            "episode: 22250 \tfinetune acc:71.250000 \t\ttest acc:63.392857\n",
            "episode: 22300 \tfinetune acc:65.000000 \t\ttest acc:58.928571\n",
            "episode: 22350 \tfinetune acc:73.750000 \t\ttest acc:63.392857\n",
            "episode: 22400 \tfinetune acc:72.500000 \t\ttest acc:65.178571\n",
            "episode: 22450 \tfinetune acc:58.750000 \t\ttest acc:63.392857\n",
            "episode: 22500 \tfinetune acc:77.500000 \t\ttest acc:71.428571\n",
            "episode: 22550 \tfinetune acc:68.750000 \t\ttest acc:60.714286\n",
            "episode: 22600 \tfinetune acc:73.750000 \t\ttest acc:60.714286\n",
            "episode: 22650 \tfinetune acc:68.750000 \t\ttest acc:60.714286\n",
            "episode: 22700 \tfinetune acc:61.250000 \t\ttest acc:66.071429\n",
            "episode: 22750 \tfinetune acc:78.750000 \t\ttest acc:58.928571\n",
            "episode: 22800 \tfinetune acc:68.750000 \t\ttest acc:61.607143\n",
            "episode: 22850 \tfinetune acc:73.750000 \t\ttest acc:63.392857\n",
            "episode: 22900 \tfinetune acc:78.750000 \t\ttest acc:66.964286\n",
            "episode: 22950 \tfinetune acc:78.750000 \t\ttest acc:64.285714\n",
            "episode: 23000 \tfinetune acc:77.500000 \t\ttest acc:56.250000\n",
            "episode: 23050 \tfinetune acc:71.250000 \t\ttest acc:65.178571\n",
            "episode: 23100 \tfinetune acc:63.750000 \t\ttest acc:62.500000\n",
            "episode: 23150 \tfinetune acc:75.000000 \t\ttest acc:58.035714\n",
            "episode: 23200 \tfinetune acc:67.500000 \t\ttest acc:60.714286\n",
            "episode: 23250 \tfinetune acc:78.750000 \t\ttest acc:58.928571\n",
            "episode: 23300 \tfinetune acc:81.250000 \t\ttest acc:60.714286\n",
            "episode: 23350 \tfinetune acc:80.000000 \t\ttest acc:56.250000\n",
            "episode: 23400 \tfinetune acc:73.750000 \t\ttest acc:68.750000\n",
            "episode: 23450 \tfinetune acc:72.500000 \t\ttest acc:61.607143\n",
            "episode: 23500 \tfinetune acc:68.750000 \t\ttest acc:68.750000\n",
            "episode: 23550 \tfinetune acc:72.500000 \t\ttest acc:69.642857\n",
            "episode: 23600 \tfinetune acc:73.750000 \t\ttest acc:60.714286\n",
            "episode: 23650 \tfinetune acc:72.500000 \t\ttest acc:54.464286\n",
            "episode: 23700 \tfinetune acc:76.250000 \t\ttest acc:57.142857\n",
            "episode: 23750 \tfinetune acc:75.000000 \t\ttest acc:66.964286\n",
            "episode: 23800 \tfinetune acc:71.250000 \t\ttest acc:59.821429\n",
            "episode: 23850 \tfinetune acc:78.750000 \t\ttest acc:62.500000\n",
            "episode: 23900 \tfinetune acc:77.500000 \t\ttest acc:59.821429\n",
            "episode: 23950 \tfinetune acc:82.500000 \t\ttest acc:59.821429\n",
            "episode: 24000 \tfinetune acc:73.750000 \t\ttest acc:66.964286\n",
            "episode: 24050 \tfinetune acc:77.500000 \t\ttest acc:64.285714\n",
            "episode: 24100 \tfinetune acc:72.500000 \t\ttest acc:66.964286\n",
            "episode: 24150 \tfinetune acc:71.250000 \t\ttest acc:64.285714\n",
            "episode: 24200 \tfinetune acc:73.750000 \t\ttest acc:66.964286\n",
            "episode: 24250 \tfinetune acc:80.000000 \t\ttest acc:57.142857\n",
            "episode: 24300 \tfinetune acc:70.000000 \t\ttest acc:67.857143\n",
            "episode: 24350 \tfinetune acc:78.750000 \t\ttest acc:67.857143\n",
            "episode: 24400 \tfinetune acc:67.500000 \t\ttest acc:59.821429\n",
            "episode: 24450 \tfinetune acc:61.250000 \t\ttest acc:61.607143\n",
            "episode: 24500 \tfinetune acc:73.750000 \t\ttest acc:66.964286\n",
            "episode: 24550 \tfinetune acc:77.500000 \t\ttest acc:65.178571\n",
            "episode: 24600 \tfinetune acc:76.250000 \t\ttest acc:65.178571\n",
            "episode: 24650 \tfinetune acc:60.000000 \t\ttest acc:60.714286\n",
            "episode: 24700 \tfinetune acc:72.500000 \t\ttest acc:60.714286\n",
            "episode: 24750 \tfinetune acc:68.750000 \t\ttest acc:65.178571\n",
            "episode: 24800 \tfinetune acc:71.250000 \t\ttest acc:67.857143\n",
            "episode: 24850 \tfinetune acc:75.000000 \t\ttest acc:63.392857\n",
            "episode: 24900 \tfinetune acc:77.500000 \t\ttest acc:57.142857\n",
            "episode: 24950 \tfinetune acc:76.250000 \t\ttest acc:54.464286\n",
            "episode: 25000 \tfinetune acc:68.750000 \t\ttest acc:68.750000\n",
            "episode: 25050 \tfinetune acc:76.250000 \t\ttest acc:64.062500\n",
            "episode: 25100 \tfinetune acc:78.750000 \t\ttest acc:65.625000\n",
            "episode: 25150 \tfinetune acc:73.750000 \t\ttest acc:68.750000\n",
            "episode: 25200 \tfinetune acc:61.250000 \t\ttest acc:61.718750\n",
            "episode: 25250 \tfinetune acc:73.750000 \t\ttest acc:64.062500\n",
            "episode: 25300 \tfinetune acc:63.750000 \t\ttest acc:61.718750\n",
            "episode: 25350 \tfinetune acc:68.750000 \t\ttest acc:65.625000\n",
            "episode: 25400 \tfinetune acc:76.250000 \t\ttest acc:59.375000\n",
            "episode: 25450 \tfinetune acc:70.000000 \t\ttest acc:58.593750\n",
            "episode: 25500 \tfinetune acc:72.500000 \t\ttest acc:67.968750\n",
            "episode: 25550 \tfinetune acc:75.000000 \t\ttest acc:67.187500\n",
            "episode: 25600 \tfinetune acc:68.750000 \t\ttest acc:58.593750\n",
            "episode: 25650 \tfinetune acc:75.000000 \t\ttest acc:64.843750\n",
            "episode: 25700 \tfinetune acc:72.500000 \t\ttest acc:65.625000\n",
            "episode: 25750 \tfinetune acc:70.000000 \t\ttest acc:60.937500\n",
            "episode: 25800 \tfinetune acc:75.000000 \t\ttest acc:60.156250\n",
            "episode: 25850 \tfinetune acc:71.250000 \t\ttest acc:60.937500\n",
            "episode: 25900 \tfinetune acc:72.500000 \t\ttest acc:70.312500\n",
            "episode: 25950 \tfinetune acc:63.750000 \t\ttest acc:64.062500\n",
            "episode: 26000 \tfinetune acc:70.000000 \t\ttest acc:69.531250\n",
            "episode: 26050 \tfinetune acc:76.250000 \t\ttest acc:65.625000\n",
            "episode: 26100 \tfinetune acc:67.500000 \t\ttest acc:60.937500\n",
            "episode: 26150 \tfinetune acc:68.750000 \t\ttest acc:63.281250\n",
            "episode: 26200 \tfinetune acc:75.000000 \t\ttest acc:62.500000\n",
            "episode: 26250 \tfinetune acc:67.500000 \t\ttest acc:63.281250\n",
            "episode: 26300 \tfinetune acc:81.250000 \t\ttest acc:56.250000\n",
            "episode: 26350 \tfinetune acc:78.750000 \t\ttest acc:57.812500\n",
            "episode: 26400 \tfinetune acc:80.000000 \t\ttest acc:60.937500\n",
            "episode: 26450 \tfinetune acc:78.750000 \t\ttest acc:69.531250\n",
            "episode: 26500 \tfinetune acc:72.500000 \t\ttest acc:66.406250\n",
            "episode: 26550 \tfinetune acc:76.250000 \t\ttest acc:61.718750\n",
            "episode: 26600 \tfinetune acc:68.750000 \t\ttest acc:64.843750\n",
            "episode: 26650 \tfinetune acc:77.500000 \t\ttest acc:56.250000\n",
            "episode: 26700 \tfinetune acc:66.250000 \t\ttest acc:60.937500\n",
            "episode: 26750 \tfinetune acc:68.750000 \t\ttest acc:64.843750\n",
            "episode: 26800 \tfinetune acc:76.250000 \t\ttest acc:63.281250\n",
            "episode: 26850 \tfinetune acc:66.250000 \t\ttest acc:56.250000\n",
            "episode: 26900 \tfinetune acc:63.750000 \t\ttest acc:69.531250\n",
            "episode: 26950 \tfinetune acc:75.000000 \t\ttest acc:63.281250\n",
            "episode: 27000 \tfinetune acc:80.000000 \t\ttest acc:62.500000\n",
            "episode: 27050 \tfinetune acc:78.750000 \t\ttest acc:62.500000\n",
            "episode: 27100 \tfinetune acc:80.000000 \t\ttest acc:63.281250\n",
            "episode: 27150 \tfinetune acc:75.000000 \t\ttest acc:60.937500\n",
            "episode: 27200 \tfinetune acc:73.750000 \t\ttest acc:60.937500\n",
            "episode: 27250 \tfinetune acc:72.500000 \t\ttest acc:61.718750\n",
            "episode: 27300 \tfinetune acc:85.000000 \t\ttest acc:57.031250\n",
            "episode: 27350 \tfinetune acc:75.000000 \t\ttest acc:62.500000\n",
            "episode: 27400 \tfinetune acc:73.750000 \t\ttest acc:60.937500\n",
            "episode: 27450 \tfinetune acc:85.000000 \t\ttest acc:58.593750\n",
            "episode: 27500 \tfinetune acc:68.750000 \t\ttest acc:63.281250\n",
            "episode: 27550 \tfinetune acc:75.000000 \t\ttest acc:69.531250\n",
            "episode: 27600 \tfinetune acc:75.000000 \t\ttest acc:61.718750\n",
            "episode: 27650 \tfinetune acc:73.750000 \t\ttest acc:56.250000\n",
            "episode: 27700 \tfinetune acc:73.750000 \t\ttest acc:63.281250\n",
            "episode: 27750 \tfinetune acc:67.500000 \t\ttest acc:54.687500\n",
            "episode: 27800 \tfinetune acc:71.250000 \t\ttest acc:61.718750\n",
            "episode: 27850 \tfinetune acc:60.000000 \t\ttest acc:65.625000\n",
            "episode: 27900 \tfinetune acc:71.250000 \t\ttest acc:56.250000\n",
            "episode: 27950 \tfinetune acc:72.500000 \t\ttest acc:68.750000\n",
            "episode: 28000 \tfinetune acc:72.500000 \t\ttest acc:56.250000\n",
            "episode: 28050 \tfinetune acc:68.750000 \t\ttest acc:63.281250\n",
            "episode: 28100 \tfinetune acc:78.750000 \t\ttest acc:57.812500\n",
            "episode: 28150 \tfinetune acc:58.750000 \t\ttest acc:59.375000\n",
            "episode: 28200 \tfinetune acc:77.500000 \t\ttest acc:62.500000\n",
            "episode: 28250 \tfinetune acc:72.500000 \t\ttest acc:64.843750\n",
            "episode: 28300 \tfinetune acc:77.500000 \t\ttest acc:61.718750\n",
            "episode: 28350 \tfinetune acc:72.500000 \t\ttest acc:65.625000\n",
            "episode: 28400 \tfinetune acc:80.000000 \t\ttest acc:57.031250\n",
            "episode: 28450 \tfinetune acc:67.500000 \t\ttest acc:58.593750\n",
            "episode: 28500 \tfinetune acc:80.000000 \t\ttest acc:68.750000\n",
            "episode: 28550 \tfinetune acc:73.750000 \t\ttest acc:61.718750\n",
            "episode: 28600 \tfinetune acc:78.750000 \t\ttest acc:61.718750\n",
            "episode: 28650 \tfinetune acc:83.750000 \t\ttest acc:57.031250\n",
            "episode: 28700 \tfinetune acc:83.750000 \t\ttest acc:56.250000\n",
            "episode: 28750 \tfinetune acc:73.750000 \t\ttest acc:57.031250\n",
            "episode: 28800 \tfinetune acc:70.000000 \t\ttest acc:60.156250\n",
            "episode: 28850 \tfinetune acc:75.000000 \t\ttest acc:57.031250\n",
            "episode: 28900 \tfinetune acc:78.750000 \t\ttest acc:68.750000\n",
            "episode: 28950 \tfinetune acc:78.750000 \t\ttest acc:60.937500\n",
            "episode: 29000 \tfinetune acc:70.000000 \t\ttest acc:57.031250\n",
            "episode: 29050 \tfinetune acc:81.250000 \t\ttest acc:66.406250\n",
            "episode: 29100 \tfinetune acc:72.500000 \t\ttest acc:66.406250\n",
            "episode: 29150 \tfinetune acc:77.500000 \t\ttest acc:57.812500\n",
            "episode: 29200 \tfinetune acc:73.750000 \t\ttest acc:55.468750\n",
            "episode: 29250 \tfinetune acc:76.250000 \t\ttest acc:57.812500\n",
            "episode: 29300 \tfinetune acc:83.750000 \t\ttest acc:66.406250\n",
            "episode: 29350 \tfinetune acc:77.500000 \t\ttest acc:58.593750\n",
            "episode: 29400 \tfinetune acc:68.750000 \t\ttest acc:73.437500\n",
            "episode: 29450 \tfinetune acc:86.250000 \t\ttest acc:60.937500\n",
            "episode: 29500 \tfinetune acc:81.250000 \t\ttest acc:67.187500\n",
            "episode: 29550 \tfinetune acc:75.000000 \t\ttest acc:56.250000\n",
            "episode: 29600 \tfinetune acc:67.500000 \t\ttest acc:60.156250\n",
            "episode: 29650 \tfinetune acc:78.750000 \t\ttest acc:55.468750\n",
            "episode: 29700 \tfinetune acc:66.250000 \t\ttest acc:68.750000\n",
            "episode: 29750 \tfinetune acc:71.250000 \t\ttest acc:60.156250\n",
            "episode: 29800 \tfinetune acc:66.250000 \t\ttest acc:60.156250\n",
            "episode: 29850 \tfinetune acc:73.750000 \t\ttest acc:65.625000\n",
            "episode: 29900 \tfinetune acc:77.500000 \t\ttest acc:70.312500\n",
            "episode: 29950 \tfinetune acc:76.250000 \t\ttest acc:66.406250\n"
          ]
        }
      ],
      "source": [
        "bciiv2a_EEGNet_Reptile, bciiv2a_data = bciiv2a(EEGNet, iterations=30000, Reptile=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "H42cCubUcN7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4962be1a-6677-4156-8160-55e50bd09012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0-shot accuracy: \tmean: 63.020833%\tstd: 12.704491%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [05:20<00:00,  4.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-shot accuracy: \tmean: 66.071429%\tstd: 8.423197%\tafter 91 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [04:45<00:00,  3.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-shot accuracy: \tmean: 65.625000%\tstd: 8.462540%\tafter 125 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [04:07<00:00,  3.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3-shot accuracy: \tmean: 66.875000%\tstd: 12.358575%\tafter 5 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:50<00:00,  3.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4-shot accuracy: \tmean: 66.666667%\tstd: 15.023130%\tafter 109 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:33<00:00,  2.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-shot accuracy: \tmean: 68.359375%\tstd: 8.405248%\tafter 5 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:31<00:00,  2.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6-shot accuracy: \tmean: 68.750000%\tstd: 9.149063%\tafter 21 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:40<00:00,  3.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7-shot accuracy: \tmean: 69.711538%\tstd: 12.219486%\tafter 71 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:48<00:00,  3.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8-shot accuracy: \tmean: 71.354167%\tstd: 11.540896%\tafter 131 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:52<00:00,  3.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9-shot accuracy: \tmean: 69.886364%\tstd: 5.849790%\tafter 79 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73/73 [03:50<00:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-shot accuracy: \tmean: 73.125000%\tstd: 12.199513%\tafter 53 updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results_bciiv2a_EEGNet_Reptile = evaluate(bciiv2a_EEGNet_Reptile, bciiv2a_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(bciiv2a_EEGNet_Reptile.net.state_dict(), 'bciiv2a_EEGNet_Reptile_checkpoint2.pth')"
      ],
      "metadata": {
        "id": "y84djV-LVNc-"
      },
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_xEOqW8k9Mvm",
        "Zla3N3Q4AjoT"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}